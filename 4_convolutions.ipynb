{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (448297, 28, 28) (448297,)\n",
      "Validation set (13649, 28, 28) (13649,)\n",
      "Test set (13649, 28, 28) (13649,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (448297, 28, 28, 1) (448297, 10)\n",
      "Validation set (13649, 28, 28, 1) (13649, 10)\n",
      "Test set (13649, 28, 28, 1) (13649, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.929373\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 0.808260\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1000: 0.891980\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 1500: 0.520008\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 2000: 0.965271\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 2500: 0.372357\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 3000: 0.197823\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 3500: 0.283527\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 4000: 2.145947\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 4500: 0.021469\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 5000: 0.683975\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 5500: 0.163847\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 6000: 0.647275\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 6500: 0.829667\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 7000: 0.286293\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 7500: 0.418407\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 8000: 0.340528\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 8500: 0.471361\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 9000: 0.460350\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 9500: 0.412808\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 10000: 0.247234\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 92.8%\n",
      "CPU times: user 1min 3s, sys: 8.37 s, total: 1min 12s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(16, 7, 7, 16), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(16, 784), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(13649, 7, 7, 16), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(13649, 784), dtype=float32)\n",
      "Tensor(\"Relu_7:0\", shape=(13649, 7, 7, 16), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(13649, 784), dtype=float32)\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3.504916\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 50: 2.216789\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 100: 1.331061\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 48.7%\n",
      "Minibatch loss at step 150: 1.107399\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 65.7%\n",
      "Minibatch loss at step 200: 0.852027\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 63.2%\n",
      "Minibatch loss at step 250: 1.041991\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 68.7%\n",
      "Minibatch loss at step 300: 0.740036\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 71.3%\n",
      "Minibatch loss at step 350: 0.694517\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 400: 0.232620\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 450: 1.423131\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 500: 1.095028\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 550: 0.433829\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 600: 0.722968\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 650: 0.536136\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 700: 0.719111\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 750: 0.797797\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 800: 0.548177\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 850: 0.979033\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 900: 0.396872\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 950: 0.643712\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1000: 0.949695\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 87.3%\n",
      "CPU times: user 14.2 s, sys: 2.48 s, total: 16.7 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.max_pool(conv,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "    hidden = tf.nn.relu(hidden + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.max_pool(conv,[1,2,2,1],[1,2,2,1],padding='SAME')    \n",
    "    hidden = tf.nn.relu(hidden + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print (hidden)    \n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    print (reshape)\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 94.6% in 10k steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(32, 7, 7, 28), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(32, 1372), dtype=float32)\n",
      "Tensor(\"Relu_5:0\", shape=(13649, 7, 7, 28), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(13649, 1372), dtype=float32)\n",
      "Tensor(\"Relu_9:0\", shape=(13649, 7, 7, 28), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(13649, 1372), dtype=float32)\n",
      "Initialized\n",
      "Minibatch loss at step 0: 23.314960\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 50: 1.299581\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 55.6%\n",
      "Minibatch loss at step 100: 1.025456\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 70.2%\n",
      "Minibatch loss at step 150: 0.679961\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 72.5%\n",
      "Minibatch loss at step 200: 0.350865\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 250: 0.739173\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 300: 0.672593\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 350: 0.859713\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 400: 0.480662\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 450: 0.500163\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 500: 1.174091\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 550: 0.845491\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 600: 0.889352\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 650: 0.485656\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 700: 1.243095\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 750: 0.362803\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 800: 0.767808\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 850: 0.598004\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 900: 0.480366\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 950: 0.826464\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 1000: 0.796044\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 1050: 0.704645\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.9%\n",
      "Minibatch loss at step 1100: 0.313487\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1150: 0.344608\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 1200: 0.286272\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 1250: 0.283881\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1300: 0.586581\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 1350: 0.531037\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1400: 0.377701\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1450: 0.589730\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 1500: 0.442809\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1550: 0.451172\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1600: 0.642966\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1650: 0.511991\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 1700: 0.339676\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1750: 0.316616\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 1800: 0.820042\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 1850: 0.419050\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1900: 0.251500\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 1950: 0.428853\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 2000: 1.630491\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2050: 0.512070\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 2100: 0.311331\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 2150: 0.946579\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 2200: 0.202489\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 2250: 0.390283\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 2300: 0.405577\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 2350: 0.339350\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 2400: 0.459365\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 2450: 0.593224\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2500: 0.790660\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 2550: 0.256322\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2600: 0.803713\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2650: 0.425514\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 2700: 0.639620\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2750: 0.561684\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 2800: 0.431766\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2850: 0.222619\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 2900: 0.303961\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2950: 0.422456\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3000: 0.512227\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 3050: 0.487349\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 3100: 0.159411\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3150: 0.586584\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3200: 0.467747\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 3250: 0.683797\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 3300: 0.459679\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3350: 0.305631\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3400: 0.324436\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3450: 0.309902\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3500: 0.477786\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 3550: 0.611211\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3600: 0.626460\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3650: 0.381322\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3700: 0.266159\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3750: 0.386885\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 3800: 0.283494\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3850: 0.786390\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3900: 0.465491\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3950: 0.177207\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4000: 0.406077\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4050: 0.315195\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 4100: 0.385449\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4150: 0.435755\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 4200: 0.616875\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 4250: 0.348020\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4300: 0.360426\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 4350: 0.538413\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4400: 0.237103\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4450: 0.227394\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4500: 0.375131\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 4550: 0.349216\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4600: 0.246977\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 4650: 0.361855\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4700: 0.379955\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4750: 0.443531\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 4800: 0.649231\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4850: 0.158486\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 4900: 0.391649\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4950: 0.049276\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5000: 0.325120\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 5050: 0.355957\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5100: 0.432696\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 5150: 0.266885\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 5200: 0.210721\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 5250: 0.479598\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 5300: 0.343003\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 5350: 0.334916\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5400: 0.427954\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5450: 0.376167\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 5500: 0.265308\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 5550: 0.322295\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 5600: 0.315131\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 5650: 0.254138\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5700: 0.465866\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5750: 0.426108\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 5800: 0.298145\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5850: 0.326612\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5900: 0.319096\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 5950: 0.314944\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 6000: 0.191801\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 6050: 0.115048\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 6100: 0.152056\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 6150: 0.433831\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 6200: 0.368693\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 6250: 0.684971\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 6300: 0.288406\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 6350: 0.230675\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 6400: 0.324677\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 6450: 0.043935\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 6500: 0.044006\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 6550: 0.281605\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 6600: 0.335991\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 6650: 0.298581\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 6700: 0.118575\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 6750: 0.296734\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 6800: 0.322893\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6850: 0.189112\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 6900: 0.110905\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 6950: 0.490267\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 7000: 0.621338\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 7050: 0.327243\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7100: 0.385413\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 7150: 0.144232\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7200: 0.277324\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 7250: 0.425119\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7300: 0.350204\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 7350: 0.221419\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7400: 0.137720\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7450: 0.323885\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 7500: 0.339943\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7550: 0.100504\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7600: 0.223969\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 7650: 0.629645\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 7700: 0.231150\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7750: 0.285132\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7800: 0.199352\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7850: 0.250552\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 7900: 0.307430\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 7950: 0.309812\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8000: 0.237018\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 8050: 0.351714\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 8100: 0.272007\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 8150: 0.064150\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 8200: 0.481046\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 8250: 0.852042\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 8300: 0.209473\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 8350: 0.514234\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 8400: 0.340731\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 8450: 0.349568\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 8500: 0.551554\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 8550: 0.605987\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 8600: 0.092658\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 8650: 0.501098\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 8700: 0.095218\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8750: 0.153449\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 8800: 0.375855\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 8850: 0.482497\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 8900: 0.502702\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 8950: 0.521122\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 9000: 0.442546\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9050: 0.634010\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 9100: 0.167711\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 9150: 0.559435\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 9200: 0.310641\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 9250: 0.331030\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9300: 0.232857\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 9350: 0.144566\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9400: 0.125659\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 9450: 0.468022\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 9500: 0.205114\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9550: 0.524390\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9600: 0.446821\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 9650: 0.520785\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 9700: 0.448482\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 9750: 0.709563\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 9800: 0.310403\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 9850: 0.223449\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 9900: 0.347603\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 9950: 0.297299\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 10000: 0.140470\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.4%\n",
      "Test accuracy: 94.6%\n",
      "CPU times: user 3min 37s, sys: 35.4 s, total: 4min 13s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 28\n",
    "num_hidden = 512\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_hidden/2], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden/2]))\n",
    "\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal([num_hidden/2, num_labels], stddev=0.1))\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.max_pool(conv,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "    hidden = tf.nn.relu(hidden + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.max_pool(conv,[1,2,2,1],[1,2,2,1],padding='SAME')    \n",
    "    hidden = tf.nn.relu(hidden + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print (hidden)    \n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    print (reshape)\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden = tf.nn.dropout(hidden,keep_prob=0.8)\n",
    "    hidden = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "    \n",
    "    return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying the best ideas from an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv [16, 28, 28, 16] [16, 14, 14, 16] [3, 3, 1, 16]\n",
      "conv [16, 14, 14, 32] [16, 7, 7, 32] [3, 3, 16, 32]\n",
      "conv [16, 7, 7, 64] [16, 4, 4, 64] [3, 3, 32, 64]\n",
      "conv [16, 4, 4, 128] [16, 2, 2, 128] [3, 3, 64, 128]\n",
      "conv [16, 2, 2, 256] [16, 1, 1, 256] [3, 3, 128, 256]\n",
      "reshaping [16, 1, 1, 256] [16, 256]\n",
      "fc [16, 256] [256, 256]\n",
      "fc [16, 64] [256, 64]\n",
      "conv [13649, 28, 28, 16] [13649, 14, 14, 16] [3, 3, 1, 16]\n",
      "conv [13649, 14, 14, 32] [13649, 7, 7, 32] [3, 3, 16, 32]\n",
      "conv [13649, 7, 7, 64] [13649, 4, 4, 64] [3, 3, 32, 64]\n",
      "conv [13649, 4, 4, 128] [13649, 2, 2, 128] [3, 3, 64, 128]\n",
      "conv [13649, 2, 2, 256] [13649, 1, 1, 256] [3, 3, 128, 256]\n",
      "reshaping [13649, 1, 1, 256] [13649, 256]\n",
      "fc [13649, 256] [256, 256]\n",
      "fc [13649, 64] [256, 64]\n",
      "conv [13649, 28, 28, 16] [13649, 14, 14, 16] [3, 3, 1, 16]\n",
      "conv [13649, 14, 14, 32] [13649, 7, 7, 32] [3, 3, 16, 32]\n",
      "conv [13649, 7, 7, 64] [13649, 4, 4, 64] [3, 3, 32, 64]\n",
      "conv [13649, 4, 4, 128] [13649, 2, 2, 128] [3, 3, 64, 128]\n",
      "conv [13649, 2, 2, 256] [13649, 1, 1, 256] [3, 3, 128, 256]\n",
      "reshaping [13649, 1, 1, 256] [13649, 256]\n",
      "fc [13649, 256] [256, 256]\n",
      "fc [13649, 64] [256, 64]\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 4.65107\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.9%\n",
      "Learning rate: 0.100000\n",
      "Minibatch loss at step 1000 : 0.828271\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.1%\n",
      "Learning rate: 0.100000\n",
      "Minibatch loss at step 2000 : 0.972792\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 85.7%\n",
      "Learning rate: 0.100000\n",
      "Minibatch loss at step 3000 : 0.157131\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.5%\n",
      "Learning rate: 0.086000\n",
      "Minibatch loss at step 4000 : 1.44068\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 86.3%\n",
      "Learning rate: 0.086000\n",
      "Minibatch loss at step 5000 : 0.502216\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.8%\n",
      "Learning rate: 0.086000\n",
      "Minibatch loss at step 6000 : 0.564749\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.7%\n",
      "Learning rate: 0.073960\n",
      "Minibatch loss at step 7000 : 0.335473\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Learning rate: 0.073960\n",
      "Minibatch loss at step 8000 : 0.485141\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.0%\n",
      "Learning rate: 0.073960\n",
      "Minibatch loss at step 9000 : 0.469347\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Learning rate: 0.063606\n",
      "Minibatch loss at step 10000 : 0.317992\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Learning rate: 0.063606\n",
      "Minibatch loss at step 11000 : 0.130302\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.8%\n",
      "Learning rate: 0.063606\n",
      "Minibatch loss at step 12000 : 0.0869986\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 89.9%\n",
      "Learning rate: 0.054701\n",
      "Minibatch loss at step 13000 : 0.00908526\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.0%\n",
      "Learning rate: 0.054701\n",
      "Minibatch loss at step 14000 : 0.547397\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.4%\n",
      "Learning rate: 0.054701\n",
      "Minibatch loss at step 15000 : 0.338577\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.1%\n",
      "Learning rate: 0.047043\n",
      "Minibatch loss at step 16000 : 0.331803\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.8%\n",
      "Learning rate: 0.047043\n",
      "Minibatch loss at step 17000 : 0.739136\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 90.7%\n",
      "Learning rate: 0.047043\n",
      "Minibatch loss at step 18000 : 0.135372\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.9%\n",
      "Learning rate: 0.040457\n",
      "Minibatch loss at step 19000 : 0.016017\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.8%\n",
      "Learning rate: 0.040457\n",
      "Minibatch loss at step 20000 : 0.154754\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Learning rate: 0.040457\n",
      "Minibatch loss at step 21000 : 0.163331\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Learning rate: 0.034793\n",
      "Minibatch loss at step 22000 : 0.214109\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Learning rate: 0.034793\n",
      "Minibatch loss at step 23000 : 0.124592\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.4%\n",
      "Learning rate: 0.034793\n",
      "Minibatch loss at step 24000 : 0.38369\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.1%\n",
      "Learning rate: 0.029922\n",
      "Minibatch loss at step 25000 : 0.434294\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.1%\n",
      "Learning rate: 0.029922\n",
      "Minibatch loss at step 26000 : 0.00649787\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.4%\n",
      "Learning rate: 0.029922\n",
      "Minibatch loss at step 27000 : 0.0254222\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.4%\n",
      "Learning rate: 0.025733\n",
      "Minibatch loss at step 28000 : 0.251478\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.4%\n",
      "Learning rate: 0.025733\n",
      "Minibatch loss at step 29000 : 0.015001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Learning rate: 0.025733\n",
      "Minibatch loss at step 30000 : 0.399309\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Learning rate: 0.022130\n",
      "Minibatch loss at step 31000 : 0.114651\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Learning rate: 0.022130\n",
      "Minibatch loss at step 32000 : 0.0137544\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Learning rate: 0.022130\n",
      "Minibatch loss at step 33000 : 0.196906\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Learning rate: 0.019032\n",
      "Minibatch loss at step 34000 : 0.45832\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Learning rate: 0.019032\n",
      "Minibatch loss at step 35000 : 0.295386\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Learning rate: 0.019032\n",
      "Minibatch loss at step 36000 : 0.379946\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Learning rate: 0.016367\n",
      "Minibatch loss at step 37000 : 0.444245\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Learning rate: 0.016367\n",
      "Minibatch loss at step 38000 : 0.52186\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Learning rate: 0.016367\n",
      "Minibatch loss at step 39000 : 0.4715\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Learning rate: 0.014076\n",
      "Minibatch loss at step 40000 : 0.0047626\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.2%\n",
      "Learning rate: 0.014076\n",
      "Minibatch loss at step 41000 : 0.25933\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Learning rate: 0.014076\n",
      "Minibatch loss at step 42000 : 0.0108948\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Learning rate: 0.012105\n",
      "Minibatch loss at step 43000 : 0.0446167\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.012105\n",
      "Minibatch loss at step 44000 : 0.0243229\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.2%\n",
      "Learning rate: 0.012105\n",
      "Minibatch loss at step 45000 : 0.213176\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.3%\n",
      "Learning rate: 0.010411\n",
      "Minibatch loss at step 46000 : 0.0831985\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Learning rate: 0.010411\n",
      "Minibatch loss at step 47000 : 0.116173\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Learning rate: 0.010411\n",
      "Minibatch loss at step 48000 : 0.145984\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Learning rate: 0.008953\n",
      "Minibatch loss at step 49000 : 0.103695\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.3%\n",
      "Learning rate: 0.008953\n",
      "Minibatch loss at step 50000 : 0.487355\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.008953\n",
      "Minibatch loss at step 51000 : 0.194268\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.007700\n",
      "Minibatch loss at step 52000 : 0.0452274\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.007700\n",
      "Minibatch loss at step 53000 : 0.239445\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.007700\n",
      "Minibatch loss at step 54000 : 0.628517\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.006622\n",
      "Minibatch loss at step 55000 : 0.246773\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Learning rate: 0.006622\n",
      "Minibatch loss at step 56000 : 0.330552\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.006622\n",
      "Minibatch loss at step 57000 : 0.00270099\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.005695\n",
      "Minibatch loss at step 58000 : 0.0239897\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.005695\n",
      "Minibatch loss at step 59000 : 0.248816\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.005695\n",
      "Minibatch loss at step 60000 : 0.235798\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.004897\n",
      "Minibatch loss at step 61000 : 0.210942\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.004897\n",
      "Minibatch loss at step 62000 : 0.381122\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.004897\n",
      "Minibatch loss at step 63000 : 0.0546367\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.004212\n",
      "Minibatch loss at step 64000 : 0.0143594\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.004212\n",
      "Minibatch loss at step 65000 : 0.19361\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.004212\n",
      "Minibatch loss at step 66000 : 0.484997\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.003622\n",
      "Minibatch loss at step 67000 : 0.0286026\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.003622\n",
      "Minibatch loss at step 68000 : 0.548883\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.003622\n",
      "Minibatch loss at step 69000 : 0.324882\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.003115\n",
      "Minibatch loss at step 70000 : 0.000201932\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Learning rate: 0.003115\n",
      "Minibatch loss at step 71000 : 0.0203075\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.003115\n",
      "Minibatch loss at step 72000 : 0.0591156\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.002679\n",
      "Minibatch loss at step 73000 : 0.226583\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.002679\n",
      "Minibatch loss at step 74000 : 0.0817419\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.002679\n",
      "Minibatch loss at step 75000 : 0.627811\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.002304\n",
      "Minibatch loss at step 76000 : 0.163844\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.002304\n",
      "Minibatch loss at step 77000 : 0.463687\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.002304\n",
      "Minibatch loss at step 78000 : 0.00577913\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001981\n",
      "Minibatch loss at step 79000 : 0.347188\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.8%\n",
      "Learning rate: 0.001981\n",
      "Minibatch loss at step 80000 : 0.206282\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001981\n",
      "Minibatch loss at step 81000 : 0.552486\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001704\n",
      "Minibatch loss at step 82000 : 0.331162\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001704\n",
      "Minibatch loss at step 83000 : 0.12136\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001704\n",
      "Minibatch loss at step 84000 : 0.249784\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001465\n",
      "Minibatch loss at step 85000 : 0.0121658\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001465\n",
      "Minibatch loss at step 86000 : 0.0443891\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001465\n",
      "Minibatch loss at step 87000 : 0.00304971\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001260\n",
      "Minibatch loss at step 88000 : 0.698458\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001260\n",
      "Minibatch loss at step 89000 : 0.00151849\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.001260\n",
      "Minibatch loss at step 90000 : 0.0348456\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001084\n",
      "Minibatch loss at step 91000 : 0.0843026\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001084\n",
      "Minibatch loss at step 92000 : 0.159976\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.001084\n",
      "Minibatch loss at step 93000 : 1.6213\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.000932\n",
      "Minibatch loss at step 94000 : 0.174076\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Learning rate: 0.000932\n",
      "Minibatch loss at step 95000 : 0.112317\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Learning rate: 0.000932\n",
      "Test accuracy: 97.2%\n",
      "CPU times: user 18min 4s, sys: 2min 28s, total: 20min 32s\n",
      "Wall time: 13min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 3\n",
    "depth = 16\n",
    "num_hidden = 256\n",
    "num_hidden_last = num_hidden/4\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    conv1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    conv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    conv2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth*2], stddev=0.1))\n",
    "    conv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "    \n",
    "    conv3_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth*2, depth*4], stddev=0.03))\n",
    "    conv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "    \n",
    "    conv4_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth*4, depth*8], stddev=0.03))\n",
    "    conv4_biases = tf.Variable(tf.zeros([depth*8]))\n",
    "    \n",
    "    conv5_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth*8, depth*16], stddev=0.03))\n",
    "    conv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "    \n",
    "    fc1_weights = tf.Variable(tf.truncated_normal([(image_size + 4) // 2**5 * (image_size + 4) // 2**5 * depth*16, num_hidden], stddev=0.03))\n",
    "    fc1_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    fc2_weights = tf.Variable(tf.truncated_normal([num_hidden, num_hidden_last], stddev=np.sqrt(2.0/num_hidden)))\n",
    "    fc2_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden_last]))\n",
    "\n",
    "    fc3_weights = tf.Variable(tf.truncated_normal([num_hidden_last, num_labels], stddev=np.sqrt(2.0/num_hidden_last)))\n",
    "    fc3_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "    def convolve(layer, weights, biases):\n",
    "        conv = tf.nn.conv2d(layer, weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.elu(conv + biases)\n",
    "        pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        print ('conv',\n",
    "               conv.get_shape().as_list(),\n",
    "               pool.get_shape().as_list(),\n",
    "               weights.get_shape().as_list())\n",
    "        return pool\n",
    "        \n",
    "    def fully_connect(layer, weights, biases, use_dropout):\n",
    "        logits = tf.nn.elu(tf.matmul(layer, weights) + biases)\n",
    "        if use_dropout:\n",
    "            logits = tf.nn.dropout(logits, keep_prob=0.75)\n",
    "        print ('fc',\n",
    "               logits.get_shape().as_list(),\n",
    "               weights.get_shape().as_list())\n",
    "        return logits\n",
    "        \n",
    "    # Model.\n",
    "    def model(data, use_dropout=False):\n",
    "        layer = convolve(data, conv1_weights, conv1_biases)\n",
    "        layer = convolve(layer, conv2_weights, conv2_biases)\n",
    "        layer = convolve(layer, conv3_weights, conv3_biases)\n",
    "        layer = convolve(layer, conv4_weights, conv4_biases)\n",
    "        layer = convolve(layer, conv5_weights, conv5_biases)\n",
    "        \n",
    "        shape = layer.get_shape().as_list()\n",
    "        reshaped_layer = tf.reshape(layer, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        reshape = reshaped_layer.get_shape().as_list()\n",
    "        print ('reshaping',shape, reshape)\n",
    "        \n",
    "        layer = fully_connect(reshaped_layer, fc1_weights, fc1_biases, use_dropout)\n",
    "        layer = fully_connect(layer, fc2_weights, fc2_biases, use_dropout)\n",
    "        return tf.matmul(layer, fc3_weights) + fc3_biases\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, use_dropout=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, 3000, 0.86, staircase=True)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "num_steps = 95001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print (\"Initialized\")\n",
    "    for step in xrange(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 1000 == 0):\n",
    "            print (\"Minibatch loss at step\", step, \":\", l)\n",
    "            print (\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print (\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "            print (\"Learning rate: %.6f\" % learning_rate.eval())\n",
    "    print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example solution 1 - 97.1% after 95000 steps by [Endri Deliu](https://discussions.udacity.com/t/assignment-4-problem-2/46525/35?u=brtknr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 28, 28, 16] [16, 14, 14, 16] [3, 3, 1, 16]\n",
      "[16, 14, 14, 32] [16, 7, 7, 32] [3, 3, 16, 32]\n",
      "[16, 7, 7, 64] [16, 4, 4, 64] [3, 3, 32, 64]\n",
      "[16, 4, 4, 128] [16, 2, 2, 128] [3, 3, 64, 128]\n",
      "[16, 2, 2, 256] [16, 1, 1, 256] [3, 3, 128, 256]\n",
      "Tensor(\"MaxPool_4:0\", shape=(16, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(16, 256), dtype=float32)\n",
      "[13649, 28, 28, 16] [13649, 14, 14, 16] [3, 3, 1, 16]\n",
      "[13649, 14, 14, 32] [13649, 7, 7, 32] [3, 3, 16, 32]\n",
      "[13649, 7, 7, 64] [13649, 4, 4, 64] [3, 3, 32, 64]\n",
      "[13649, 4, 4, 128] [13649, 2, 2, 128] [3, 3, 64, 128]\n",
      "[13649, 2, 2, 256] [13649, 1, 1, 256] [3, 3, 128, 256]\n",
      "Tensor(\"MaxPool_9:0\", shape=(13649, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(13649, 256), dtype=float32)\n",
      "[13649, 28, 28, 16] [13649, 14, 14, 16] [3, 3, 1, 16]\n",
      "[13649, 14, 14, 32] [13649, 7, 7, 32] [3, 3, 16, 32]\n",
      "[13649, 7, 7, 64] [13649, 4, 4, 64] [3, 3, 32, 64]\n",
      "[13649, 4, 4, 128] [13649, 2, 2, 128] [3, 3, 64, 128]\n",
      "[13649, 2, 2, 256] [13649, 1, 1, 256] [3, 3, 128, 256]\n",
      "Tensor(\"MaxPool_14:0\", shape=(13649, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(13649, 256), dtype=float32)\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 2.30403\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 500 : 0.588366\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1000 : 0.580849\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 1500 : 0.196564\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 2000 : 0.886516\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2500 : 0.348034\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3000 : 0.187954\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3500 : 0.392232\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4000 : 1.62871\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 4500 : 0.0522279\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5000 : 0.560489\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 5500 : 0.279258\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 6000 : 0.531829\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 6500 : 0.691851\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7000 : 0.345505\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 7500 : 0.365863\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 8000 : 0.262874\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8500 : 0.505553\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 9000 : 0.262893\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 9500 : 0.10222\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 10000 : 0.235856\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 10500 : 0.443725\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11000 : 0.187249\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11500 : 0.376514\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 12000 : 0.208384\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 12500 : 0.407972\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13000 : 0.0345362\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 13500 : 0.256159\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 14000 : 0.578848\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 14500 : 0.103301\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 15000 : 0.320173\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 15500 : 0.116391\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16000 : 0.408232\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 16500 : 0.942134\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 17000 : 0.75772\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17500 : 0.0132841\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 18000 : 0.23117\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18500 : 0.395782\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 19000 : 0.0372725\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 19500 : 0.534268\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 20000 : 0.128322\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20500 : 0.190156\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 21000 : 0.0555952\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 21500 : 0.400025\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22000 : 0.335921\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22500 : 0.385998\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23000 : 0.199565\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 23500 : 0.314457\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 24000 : 0.481303\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24500 : 0.31091\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 25000 : 0.51213\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25500 : 0.316373\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26000 : 0.0119028\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26500 : 0.370707\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 27000 : 0.0213153\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27500 : 0.232575\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 28000 : 0.374038\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 28500 : 0.649919\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29000 : 0.0826611\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 29500 : 0.493862\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30000 : 0.348699\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30500 : 0.195787\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 31000 : 0.0633114\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 31500 : 0.578289\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32000 : 0.0191195\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32500 : 0.104966\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33000 : 0.175848\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33500 : 0.086549\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34000 : 0.498291\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 34500 : 0.384202\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35000 : 0.224626\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 35500 : 0.0402492\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36000 : 0.310914\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 36500 : 0.163184\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37000 : 0.358921\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37500 : 0.121495\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38000 : 0.477789\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 38500 : 0.117244\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39000 : 0.317009\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39500 : 0.426553\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40000 : 0.00498731\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40500 : 0.139097\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41000 : 0.218473\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41500 : 0.196459\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 42000 : 0.0830774\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42500 : 0.484298\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 43000 : 0.0347461\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 43500 : 0.145605\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44000 : 0.0129565\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44500 : 0.188839\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45000 : 0.299703\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45500 : 0.622438\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 46000 : 0.0583822\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 46500 : 0.257355\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47000 : 0.122172\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 47500 : 0.11277\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48000 : 0.113486\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48500 : 0.262152\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49000 : 0.144991\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 49500 : 0.337175\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 50000 : 0.346104\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 50500 : 0.00703503\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 51000 : 0.204956\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 51500 : 0.0404387\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 52000 : 0.0585213\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 52500 : 0.37419\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 53000 : 0.134536\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 53500 : 0.633621\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 54000 : 0.478553\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 54500 : 0.0418645\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 55000 : 0.338737\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 55500 : 0.00424903\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 56000 : 0.313913\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 56500 : 0.333644\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 57000 : 0.00841578\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 57500 : 1.05019\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 58000 : 0.033983\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 58500 : 0.23404\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 59000 : 0.163564\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 59500 : 0.162632\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 60000 : 0.30969\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 60500 : 0.62821\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 61000 : 0.271181\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 61500 : 0.286572\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 62000 : 0.394909\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 62500 : 0.0387042\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 63000 : 0.0543951\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 63500 : 0.00762959\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 64000 : 0.0220043\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 64500 : 0.278635\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 65000 : 0.249745\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 65500 : 0.10424\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 66000 : 0.426997\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 66500 : 0.00346257\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 67000 : 0.0543061\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 67500 : 0.0495015\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 68000 : 0.377498\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 68500 : 0.237428\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 69000 : 0.340036\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 69500 : 0.578117\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 70000 : 0.000349628\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 70500 : 0.0628962\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 71000 : 0.0146571\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 71500 : 0.216701\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 72000 : 0.128077\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 72500 : 0.002581\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 73000 : 0.198505\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 73500 : 0.0168444\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 74000 : 0.0199261\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 74500 : 0.157868\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 75000 : 0.595328\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 75500 : 0.472988\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 76000 : 0.113001\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 76500 : 0.0791961\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 77000 : 0.539787\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 77500 : 0.128359\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 78000 : 0.015828\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 78500 : 0.627581\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 79000 : 0.444282\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 79500 : 0.00289366\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 80000 : 0.289335\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 80500 : 0.129337\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 81000 : 0.580352\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 81500 : 0.053401\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 82000 : 0.435658\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 82500 : 0.0293399\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 83000 : 0.0558719\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 83500 : 0.0653625\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 84000 : 0.289561\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 84500 : 0.158373\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 85000 : 0.0116273\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 85500 : 0.00242327\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 86000 : 0.0263457\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 86500 : 0.546794\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 87000 : 0.00277916\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 87500 : 0.068024\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 88000 : 0.721094\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 88500 : 0.0133948\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 89000 : 0.00438258\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 89500 : 0.209388\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 90000 : 0.0393521\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 90500 : 0.392455\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 91000 : 0.0330899\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 91500 : 0.0723718\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 92000 : 0.0968305\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 92500 : 0.00795362\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 93000 : 1.32511\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 93500 : 0.405289\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 94000 : 0.154716\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 94500 : 0.173018\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 95000 : 0.293016\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.8%\n",
      "Test accuracy: 97.2%\n",
      "CPU times: user 18min 46s, sys: 2min 26s, total: 21min 13s\n",
      "Wall time: 13min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 3\n",
    "depth = 16\n",
    "num_hidden = 256\n",
    "num_hidden_last = 128\n",
    "stride = 2\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerconv1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerconv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "\n",
    "  layerconv2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth * 2], stddev=0.1))\n",
    "  layerconv2_biases = tf.Variable(tf.zeros([depth * 2]))\n",
    "    \n",
    "  layerconv3_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth * 2, depth * 4], stddev=0.03))\n",
    "  layerconv3_biases = tf.Variable(tf.zeros([depth * 4]))\n",
    "  \n",
    "  layerconv4_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth * 4, depth * 8], stddev=0.03))\n",
    "  layerconv4_biases = tf.Variable(tf.zeros([depth * 8]))\n",
    "  \n",
    "  layerconv5_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth * 8, depth * 16], stddev=0.03))\n",
    "  layerconv5_biases = tf.Variable(tf.zeros([depth * 16]))\n",
    "\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 28 * image_size // 28 * (depth*16), num_hidden], stddev=0.03))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_hidden]))\n",
    "\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_hidden_last], stddev=0.0532))\n",
    "  layer4_biases = tf.Variable(tf.zeros([num_hidden_last]))\n",
    "\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal([num_hidden_last, num_labels], stddev=0.1))\n",
    "  layer5_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerconv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    print (conv.get_shape().as_list(),\n",
    "           pool.get_shape().as_list(),\n",
    "           layerconv1_weights.get_shape().as_list())\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv2_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    print (conv.get_shape().as_list(),\n",
    "           pool.get_shape().as_list(),\n",
    "           layerconv2_weights.get_shape().as_list())\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    print (conv.get_shape().as_list(),\n",
    "           pool.get_shape().as_list(),\n",
    "           layerconv3_weights.get_shape().as_list())\n",
    "    # norm1\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    print (conv.get_shape().as_list(),\n",
    "       pool.get_shape().as_list(),\n",
    "       layerconv4_weights.get_shape().as_list())\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    conv = tf.nn.conv2d(pool, layerconv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    print (conv.get_shape().as_list(),\n",
    "           pool.get_shape().as_list(),\n",
    "           layerconv5_weights.get_shape().as_list())\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    shape = pool.get_shape().as_list()\n",
    "    print (pool)\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    print (reshape)\n",
    "    logits = tf.matmul(reshape, layer3_weights) + layer3_biases\n",
    "    hidden = tf.nn.elu(logits)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    logits = tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    hidden = tf.nn.elu(logits)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    \n",
    "    return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, use_dropout=True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 3000, 0.86, staircase=True)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "\n",
    "num_steps = 95001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print (\"Initialized\")\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print (\"Minibatch loss at step\", step, \":\", l)\n",
    "      print (\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print (\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But 94.4% in 10k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 2, 2, 256]\n",
      "[13649, 2, 2, 256]\n",
      "[13649, 2, 2, 256]\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 2.29201\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 11.1%\n",
      "Minibatch loss at step 500 : 0.438783\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 1000 : 0.910752\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 1500 : 0.233955\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 2000 : 0.914765\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2500 : 0.336413\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3000 : 0.218305\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3500 : 0.416173\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 4000 : 1.59111\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 4500 : 0.0347821\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5000 : 0.57787\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5500 : 0.229866\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 6000 : 0.583779\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 6500 : 0.766438\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7000 : 0.40708\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 7500 : 0.361787\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 8000 : 0.315769\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 8500 : 0.340751\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 9000 : 0.237157\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 9500 : 0.213278\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 10000 : 0.342112\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.4%\n",
      "CPU times: user 2min 20s, sys: 19.3 s, total: 2min 39s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 16\n",
    "patch_size = 3\n",
    "depth = 16\n",
    "num_hidden = 705\n",
    "num_hidden_last = 205\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerconv1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerconv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerconv2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth * 2], stddev=0.1))\n",
    "  layerconv2_biases = tf.Variable(tf.zeros([depth * 2]))\n",
    "  \n",
    "  layerconv3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth * 2, depth * 4], stddev=0.03))\n",
    "  layerconv3_biases = tf.Variable(tf.zeros([depth * 4]))\n",
    "  \n",
    "  layerconv4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth * 4, depth * 4], stddev=0.03))\n",
    "  layerconv4_biases = tf.Variable(tf.zeros([depth * 4]))\n",
    "  \n",
    "\n",
    "  layerconv5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth * 4, depth * 16], stddev=0.03))\n",
    "  layerconv5_biases = tf.Variable(tf.zeros([depth * 16]))\n",
    "\n",
    "    \n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size / 7 * image_size / 7 * (depth * 4), num_hidden], stddev=0.03))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_hidden_last], stddev=0.0532))\n",
    "  layer4_biases = tf.Variable(tf.zeros([num_hidden_last]))\n",
    "  \n",
    "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden_last, num_labels], stddev=0.1))\n",
    "  layer5_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "\n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerconv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv2_biases)\n",
    "    #pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerconv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    # norm1\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerconv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerconv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    # norm1 = tf.nn.lrn(pool, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    shape = pool.get_shape().as_list()\n",
    "    print (shape)\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    \n",
    "    return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 3000, 0.86, staircase=True)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print (\"Initialized\")\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print (\"Minibatch loss at step\", step, \":\", l)\n",
    "      print (\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print (\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example solution 2 - 94.5% in 30k steps by [Kobi Bento](https://discussions.udacity.com/t/assignment-4-problem-2/46525/54?u=brtknr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 28, 28, 1]\n",
      "[16, 28, 28, 6]\n",
      "[16, 14, 14, 6]\n",
      "[16, 7, 7, 16]\n",
      "[16, 4, 4, 120]\n",
      "[13649, 28, 28, 1]\n",
      "[13649, 28, 28, 6]\n",
      "[13649, 14, 14, 6]\n",
      "[13649, 7, 7, 16]\n",
      "[13649, 4, 4, 120]\n",
      "[13649, 28, 28, 1]\n",
      "[13649, 28, 28, 6]\n",
      "[13649, 14, 14, 6]\n",
      "[13649, 7, 7, 16]\n",
      "[13649, 4, 4, 120]\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 12.3073\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 7.3%\n",
      "Minibatch loss at step 500 : 2.30312\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000 : 2.30001\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 1500 : 2.29376\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 2000 : 2.29285\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 2500 : 2.30703\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 3000 : 2.29797\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.8%\n",
      "Minibatch loss at step 3500 : 2.2893\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 4000 : 2.30204\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 4500 : 2.29995\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 5000 : 2.2954\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 5500 : 2.30468\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 6000 : 2.30601\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 6500 : 2.29605\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 7000 : 2.3076\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 7500 : 2.29881\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 8000 : 1.83765\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 17.7%\n",
      "Minibatch loss at step 8500 : 0.854606\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 9000 : 0.544549\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 9500 : 0.497018\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 10000 : 0.5157\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 10500 : 0.788124\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 11000 : 0.227759\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 11500 : 0.500903\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 12000 : 0.504806\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 12500 : 0.853945\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 13000 : 0.0676701\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 13500 : 0.391991\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 14000 : 0.697277\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 14500 : 0.329516\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 15000 : 0.752212\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 15500 : 0.622251\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 16000 : 0.470618\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 16500 : 0.983063\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 17000 : 0.852206\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 17500 : 0.189771\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 18000 : 0.400313\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 18500 : 0.466393\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 19000 : 0.00480082\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 19500 : 0.798406\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 20000 : 0.111417\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 20500 : 0.271243\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 21000 : 0.237059\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 21500 : 0.384614\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 22000 : 0.34556\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 22500 : 0.447887\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 23000 : 0.250214\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 23500 : 0.483804\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 24000 : 0.514005\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 24500 : 0.383858\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 25000 : 0.504547\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 25500 : 0.359072\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 26000 : 0.0295484\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 26500 : 0.541196\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 27000 : 0.137441\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 27500 : 0.15861\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 28000 : 0.329663\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 28500 : 1.08813\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 29000 : 0.2677\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 29500 : 0.595806\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 30000 : 0.619808\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_channels = 1\n",
    "\n",
    "c1_depth = 6\n",
    "c1_ker_sz = 5\n",
    "c3_depth = 16\n",
    "c3_ker_sz = 6\n",
    "c5_depth = 120\n",
    "c5_ker_sz = 6\n",
    "\n",
    "num_hidden = 84\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    c1_weights = tf.Variable(tf.truncated_normal([c1_ker_sz, c1_ker_sz, num_channels, c1_depth], stddev=0.1))\n",
    "    c1_biases = tf.Variable(tf.zeros([c1_depth]))\n",
    "    c3_weights = tf.Variable(tf.truncated_normal([c3_ker_sz, c3_ker_sz, c1_depth, c3_depth], stddev=0.1))\n",
    "    c3_biases = tf.Variable(tf.constant(1.0, shape=[c3_depth]))\n",
    "    c5_weights = tf.Variable(tf.truncated_normal([c5_ker_sz, c5_ker_sz, c3_depth, c5_depth], stddev=0.1))\n",
    "    c5_biases = tf.Variable(tf.constant(1.0, shape=[c5_depth]))\n",
    "    c5_conv_dim = (((((image_size+1)//2) + 1) // 2) + 1 )//2\n",
    "    fc_weights = tf.Variable(tf.truncated_normal([c5_conv_dim * c5_conv_dim * c5_depth, num_hidden], stddev=0.1))\n",
    "    fc_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    out_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    out_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        print(data.get_shape().as_list())\n",
    "        conv = tf.nn.conv2d(data, c1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c1_biases)\n",
    "        print(conv.get_shape().as_list())\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        print(pooled.get_shape().as_list())\n",
    "        conv = tf.nn.conv2d(pooled, c3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c3_biases)\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        shape = pooled.get_shape().as_list()\n",
    "        print(shape)\n",
    "        conv = tf.nn.conv2d(pooled, c5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c5_biases)\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        shape = pooled.get_shape().as_list()\n",
    "        print(shape)\n",
    "        reshape = tf.reshape(pooled, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, fc_weights) + fc_biases)\n",
    "        return tf.matmul(hidden, out_weights) + out_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "    # Optimizer.\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    optimizer = tf.train.AdagradOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "    \n",
    "num_steps = 30001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print (\"Initialized\")\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print (\"Minibatch loss at step\", step, \":\", l)\n",
    "      print (\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print (\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However in 10k steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 28, 28, 1]\n",
      "[16, 28, 28, 6]\n",
      "[16, 14, 14, 6]\n",
      "[16, 7, 7, 16]\n",
      "[16, 4, 4, 120]\n",
      "[13649, 28, 28, 1]\n",
      "[13649, 28, 28, 6]\n",
      "[13649, 14, 14, 6]\n",
      "[13649, 7, 7, 16]\n",
      "[13649, 4, 4, 120]\n",
      "[13649, 28, 28, 1]\n",
      "[13649, 28, 28, 6]\n",
      "[13649, 14, 14, 6]\n",
      "[13649, 7, 7, 16]\n",
      "[13649, 4, 4, 120]\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 8.93694\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 500 : 2.30322\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000 : 2.29927\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 1500 : 2.29383\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 2000 : 2.29308\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 2500 : 2.30724\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 3000 : 2.29782\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.8%\n",
      "Minibatch loss at step 3500 : 2.28924\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 4000 : 2.30232\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 4500 : 2.3\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.3%\n",
      "Minibatch loss at step 5000 : 2.29536\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 5500 : 2.30465\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 6000 : 2.306\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 6500 : 2.29604\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 7000 : 2.3076\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 7500 : 2.29879\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 8000 : 2.29267\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 8500 : 2.30044\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 9000 : 2.29733\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 9500 : 2.28872\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.3%\n",
      "Minibatch loss at step 10000 : 1.26814\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 71.2%\n",
      "Test accuracy: 76.9%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_channels = 1\n",
    "\n",
    "c1_depth = 6\n",
    "c1_ker_sz = 5\n",
    "c3_depth = 16\n",
    "c3_ker_sz = 6\n",
    "c5_depth = 120\n",
    "c5_ker_sz = 6\n",
    "\n",
    "num_hidden = 84\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    c1_weights = tf.Variable(tf.truncated_normal([c1_ker_sz, c1_ker_sz, num_channels, c1_depth], stddev=0.1))\n",
    "    c1_biases = tf.Variable(tf.zeros([c1_depth]))\n",
    "    c3_weights = tf.Variable(tf.truncated_normal([c3_ker_sz, c3_ker_sz, c1_depth, c3_depth], stddev=0.1))\n",
    "    c3_biases = tf.Variable(tf.constant(1.0, shape=[c3_depth]))\n",
    "    c5_weights = tf.Variable(tf.truncated_normal([c5_ker_sz, c5_ker_sz, c3_depth, c5_depth], stddev=0.1))\n",
    "    c5_biases = tf.Variable(tf.constant(1.0, shape=[c5_depth]))\n",
    "    c5_conv_dim = (((((image_size+1)//2) + 1) // 2) + 1 )//2\n",
    "    fc_weights = tf.Variable(tf.truncated_normal([c5_conv_dim * c5_conv_dim * c5_depth, num_hidden], stddev=0.1))\n",
    "    fc_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    out_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    out_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        print(data.get_shape().as_list())\n",
    "        conv = tf.nn.conv2d(data, c1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c1_biases)\n",
    "        print(conv.get_shape().as_list())\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        print(pooled.get_shape().as_list())\n",
    "        conv = tf.nn.conv2d(pooled, c3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c3_biases)\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        shape = pooled.get_shape().as_list()\n",
    "        print(shape)\n",
    "        conv = tf.nn.conv2d(pooled, c5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + c5_biases)\n",
    "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        shape = pooled.get_shape().as_list()\n",
    "        print(shape)\n",
    "        reshape = tf.reshape(pooled, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, fc_weights) + fc_biases)\n",
    "        return tf.matmul(hidden, out_weights) + out_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "    # Optimizer.\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    optimizer = tf.train.AdagradOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "    \n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print (\"Initialized\")\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print (\"Minibatch loss at step\", step, \":\", l)\n",
    "      print (\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print (\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
